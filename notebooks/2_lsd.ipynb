{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lsd\n",
    "#|export\n",
    "\n",
    "from perturbative_llm_cognition import core\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37797a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from hmac import new\n",
    "\n",
    "\n",
    "class LSDPerturbedLLM:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        layer_start: int = 21,                              # Start layer to perturb    \n",
    "        layer_end: int = 30,                                # Final layer to perturb\n",
    "        attention_temperature_initial: float = 1.20,         # Temperature > 1 flattens attention (scores /= temperature)\n",
    "        attention_diagonal_penalty_initial: float = 0.40,    # Subtract at most-recent key at decode (q_len==1)\n",
    "        swiglu_skew_initial: float = 0.15,                   # Magnitude skew exponent\n",
    "        swiglu_noise_initial: float = 0.12,                  # Structured noise scale (zero-mean) <- better name required\n",
    "        js_tolerance: float = 0.12,                         # Tolerated JS divergence before clamping gets strong\n",
    "        #js_softness: float = 0.1,                          # Sigmoid softness around the tolerance <- better name required\n",
    "        divergence_smoothing_factor: float = 0.8,                              # EMA smoothing for JS\n",
    "        teacher_blend_min: float = 0.10,                    # Min teacher blend weight\n",
    "        teacher_blend_max: float = 0.60,  \n",
    "        debug: bool = False                  # Max teacher blend weight when drift is high\n",
    "        ):\n",
    "\n",
    "        self.layer_start = max(layer_start, 0)\n",
    "        self.layer_end = max(layer_end, 31)\n",
    "        self.js_tolerance = max(0.0, js_tolerance)\n",
    "        #self.js_softness = max(0.0, js_softness)\n",
    "        self.divergence_smoothing_factor = max(0.0, divergence_smoothing_factor)\n",
    "        self.teacher_blend_min = max(0.0, teacher_blend_min)\n",
    "        self.teacher_blend_max = min(1.0, teacher_blend_max)\n",
    "\n",
    "        if self.teacher_blend_min > self.teacher_blend_max:\n",
    "            raise ValueError('Invalid teacher parameters')\n",
    "\n",
    "        self.set_perturbation_parameters(\n",
    "            attention_temperature=attention_temperature_initial,\n",
    "            attention_diagonal_penalty=attention_diagonal_penalty_initial,\n",
    "            teacher_blend= teacher_blend_min + (teacher_blend_max - teacher_blend_min) * 0.5,\n",
    "            #swiglu_skew_target=swiglu_skew_target,\n",
    "            #swiglu_noise_target=swiglu_noise_target,\n",
    "        )\n",
    "\n",
    "        self.tokenizer, self.model = core.load_tokenizer_and_model()\n",
    "        self.model.config.attn_implementation = 'eager'\n",
    "        self.model.config._attn_implementation = 'eager'  # Also try this\n",
    "        self.device = self.model.device\n",
    "\n",
    "        self._store_original_attention_functions()\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "    def set_perturbation_parameters(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Clamps all perturbation parameters to valid ranges.\n",
    "        \"\"\"\n",
    "\n",
    "        for parameter, value in kwargs.items():\n",
    "            if parameter in ['attention_temperature']:\n",
    "                setattr(self, parameter, min(max(1.0, value), 2.0))\n",
    "            \n",
    "            elif parameter in ['attention_diagonal_penalty']:\n",
    "                setattr(self, parameter, min(max(0.0, value), 1.0))\n",
    "            \n",
    "            elif parameter in ['teacher_blend']:\n",
    "                setattr(self, parameter, max(self.teacher_blend_min, min(self.teacher_blend_max, value)))\n",
    "            else:\n",
    "                setattr(self, parameter, max(0.0, value))\n",
    "\n",
    "    def _store_original_attention_functions(self):\n",
    "        \"\"\"Store original attention forward functions for reset capability\"\"\"\n",
    "        self.original_attention_forwards = {}\n",
    "        for i, block in enumerate(self.model.model.layers):\n",
    "            if self.is_target_layer(i):\n",
    "                self.original_attention_forwards[i] = block.self_attn.forward\n",
    "\n",
    "    def reset_to_base_model(self):\n",
    "        \"\"\"Completely reset model to base state by restoring original functions\"\"\"\n",
    "        for i, block in enumerate(self.model.model.layers):\n",
    "            if self.is_target_layer(i) and i in self.original_attention_forwards:\n",
    "                block.self_attn.forward = self.original_attention_forwards[i]\n",
    "\n",
    "    def is_target_layer(self, index: int) -> bool:\n",
    "        return self.layer_start <= index < self.layer_end\n",
    "\n",
    "    def apply_perturbation(self):\n",
    "        \"\"\"Apply perturbations while preserving original functions\"\"\"\n",
    "        # Always recreate the perturbation functions to get updated parameters\n",
    "        #self.apply_attention_perturbation()\n",
    "        for i, block in enumerate(self.model.model.layers):\n",
    "            if self.is_target_layer(i):\n",
    "                original_forward = block.self_attn.forward\n",
    "                num_heads = self.model.config.num_attention_heads\n",
    "                head_dim = self.model.config.hidden_size // num_heads\n",
    "                num_kv_heads = getattr(self.model.config, 'num_key_value_heads', num_heads // 4)\n",
    "                v_proj = block.self_attn.v_proj\n",
    "                o_proj = block.self_attn.o_proj\n",
    "\n",
    "                block.self_attn.forward = self.create_perturbed_forward(original_forward, num_heads, head_dim, num_kv_heads, v_proj, o_proj, i)\n",
    "\n",
    "    def create_perturbed_forward(self, original_forward, num_heads, head_dim, num_kv_heads, v_proj, o_proj, layer_idx):\n",
    "        \n",
    "        def perturbed_forward(*args, **kwargs):\n",
    "            if self.debug:\n",
    "                print(f\"DEBUG: Perturbed attention called for layer {layer_idx}\")\n",
    "            \n",
    "            # Extract hidden_states from kwargs\n",
    "            hidden_states = kwargs.get('hidden_states', args[0] if len(args) > 0 else None)\n",
    "            \n",
    "            if hidden_states is None:\n",
    "                print(\"WARNING: Could not find hidden_states\")\n",
    "                return original_forward(*args, **kwargs)\n",
    "            \n",
    "            # Get dimensions\n",
    "            batch_size, seq_len, hidden_size = hidden_states.shape\n",
    "            \n",
    "            # Get KV heads and repeat groups from config\n",
    "            groups = num_heads // num_kv_heads\n",
    "            \n",
    "            # Project to get value states (this gives us 1024 = num_kv_heads * head_dim)\n",
    "            value_states = v_proj(hidden_states)  # [B, T, 1024]\n",
    "            \n",
    "            # Reshape value states for multi-head attention (KV heads)\n",
    "            value_states = value_states.view(batch_size, seq_len, num_kv_heads, head_dim).transpose(1, 2)  # [B, num_kv_heads, T, head_dim]\n",
    "            \n",
    "            # Handle past key values if they exist\n",
    "            past_key_values = kwargs.get('past_key_values', None)\n",
    "            layer_cache = past_key_values.layers[layer_idx]\n",
    "            past_values = layer_cache.values\n",
    "            \n",
    "            if past_values is not None:\n",
    "                # Concatenate past values with current values\n",
    "                value_states = torch.cat([past_values, value_states], dim=2)\n",
    "            \n",
    "            # Repeat KV to match Q heads (this is the key part!)\n",
    "            if groups > 1:\n",
    "                value_states = value_states.unsqueeze(2).expand(batch_size, num_kv_heads, groups, value_states.size(2), head_dim)\n",
    "                value_states = value_states.reshape(batch_size, num_heads, value_states.size(3), head_dim)\n",
    "            \n",
    "            # Call original forward to get attention weights\n",
    "            result = original_forward(*args, **kwargs)\n",
    "            \n",
    "            # Extract attention weights\n",
    "            if isinstance(result, tuple) and len(result) >= 2:\n",
    "                if len(result) == 2:\n",
    "                    attn_output, attn_weights = result\n",
    "                else:\n",
    "                    attn_output, attn_weights, past_values = result\n",
    "\n",
    "                if attn_weights is not None:                    \n",
    "                    # Apply your modifications to the attention weights\n",
    "                    modified_weights = attn_weights.clone()\n",
    "                    \n",
    "                    # Temperature scaling\n",
    "                    modified_weights = modified_weights / self.attention_temperature\n",
    "                    \n",
    "                    # Diagonal penalty for decode step\n",
    "                    if modified_weights.size(-2) == 1:\n",
    "                        modified_weights[..., -1] = modified_weights[..., -1] - self.attention_diagonal_penalty\n",
    "\n",
    "                    # Apply softmax to get attention probabilities\n",
    "                    modified_weights = torch.softmax(modified_weights, dim=-1)\n",
    "                    \n",
    "                    # Apply modified attention weights to values\n",
    "                    #print(f\"Modified weights shape: {modified_weights.shape}\")\n",
    "                    #print(f\"Value states shape: {value_states.shape}\")\n",
    "                    #print(f\"Expected matmul: {modified_weights.shape} @ {value_states.shape}\")\n",
    "                    attn_output = torch.matmul(modified_weights, value_states)\n",
    "                    \n",
    "                    # Reshape back to original format\n",
    "                    attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, num_heads * head_dim)\n",
    "                    \n",
    "                    # Apply output projection\n",
    "                    attn_output = o_proj(attn_output)\n",
    "                    \n",
    "                    if self.debug:\n",
    "                        print(f\"Applied modifications: tau={self.attention_temperature}, diag={self.attention_diagonal_penalty}\")\n",
    "                    \n",
    "                    return attn_output, modified_weights\n",
    "                    if past_values is not None:\n",
    "                        return attn_output, modified_weights, past_values\n",
    "                    \n",
    "            \n",
    "            return result\n",
    "            \n",
    "        return perturbed_forward\n",
    "\n",
    "    @staticmethod\n",
    "    def js_divergence(p, q, epsilon=1e-6, threshold=1e-6):\n",
    "        \n",
    "\n",
    "        mask = (p > threshold) | (q > threshold)\n",
    "    \n",
    "        if mask.sum() == 0:\n",
    "            raise ValueError('No valid probabilities found in input distributions')\n",
    "        \n",
    "        p = p[mask]\n",
    "        q = q[mask]\n",
    "\n",
    "        # Add small epsilon to avoid log(0) issues\n",
    "        p = p + epsilon\n",
    "        q = q + epsilon\n",
    "        # Renormalise\n",
    "        p = p / p.sum(-1, keepdim=True)\n",
    "        q = q / q.sum(-1, keepdim=True)\n",
    "        \n",
    "        m = 0.5 * (p + q)\n",
    "\n",
    "        def kl(a, b):\n",
    "            return (a * (torch.log(a) - torch.log(b))).sum(-1)\n",
    "\n",
    "        return 0.5 * kl(p, m) + 0.5 * kl(q, m)\n",
    "\n",
    "    def step(self, pert_logits, base_logits):\n",
    "        # Debug: check if logits are identical\n",
    "        are_identical = torch.allclose(pert_logits, base_logits, atol=1e-6)\n",
    "        if are_identical:\n",
    "            print(\"WARNING: Perturbed and base logits are identical!\")\n",
    "\n",
    "        # Distributions\n",
    "        p_base = torch.softmax(base_logits, dim=-1)\n",
    "        p_pert = torch.softmax(pert_logits, dim=-1)\n",
    "        \n",
    "        # JS divergence (batch-mean scalar)\n",
    "        divergence = self.js_divergence(p_pert, p_base).mean().item()\n",
    "        if np.isnan(divergence):\n",
    "            print(f'nan divergence: {divergence}')\n",
    "            divergence = 0.0\n",
    "            \n",
    "        # EMA\n",
    "        self.running_divergence = self.divergence_smoothing_factor * self.running_divergence + (1 - self.divergence_smoothing_factor) * divergence\n",
    "        # Gain (high drift → backwards step, low drift → forwards step)\n",
    "\n",
    "        divergence = divergence * 100\n",
    "        running_divergence = divergence * 100\n",
    "        js_tolerance = self.js_tolerance * 100\n",
    "\n",
    "        step_size = ((js_tolerance -running_divergence) / js_tolerance)\n",
    "        step_size = min(max(-0.5, step_size), 0.25)\n",
    "        step_size = 1 + step_size\n",
    "\n",
    "        print(divergence)\n",
    "        print(self.running_divergence)\n",
    "        print(step_size)\n",
    "\n",
    "        # Effective strengths\n",
    "        attention_temperature  = 1.0 + (self.attention_temperature - 1.0) * step_size\n",
    "        attention_diagonal_penalty = self.attention_diagonal_penalty * step_size\n",
    "\n",
    "\n",
    "        teacher_blend_percentage = ((js_tolerance - divergence) / js_tolerance)\n",
    "        teacher_blend_percentage = min(max(0.0, teacher_blend_percentage), 1.0)\n",
    "        teacher_blend = self.teacher_blend_max - (self.teacher_blend_max - self.teacher_blend_min) * teacher_blend_percentage\n",
    "\n",
    "        #teacher_blend_ratio = ((self.teacher_blend - self.teacher_blend_min) / (self.teacher_blend_max - self.teacher_blend_min)) * (2-step_size)\n",
    "        #teacher_blend = self.teacher_blend_min + (self.teacher_blend_max - self.teacher_blend_min) * teacher_blend_ratio\n",
    "\n",
    "        \n",
    "        #skew_eff = self.cfg.swiglu_skew_target * g\n",
    "        #noise_eff= self.cfg.swiglu_noise_target * g\n",
    "\n",
    "        # Teacher blend increases as drift grows (g small)\n",
    "        #teacher_blend = self.teacher_blend_min + min(0,(1 - step_size)) * (self.teacher_blend_max - self.teacher_blend_min)\n",
    "        return {\n",
    "            \"attention_temperature\": float(attention_temperature),\n",
    "            \"attention_diagonal_penalty\": float(attention_diagonal_penalty),\n",
    "            #\"skew_eff\": float(skew_eff),\n",
    "            #\"noise_eff\": float(noise_eff),\n",
    "            \"teacher_blend\": float(teacher_blend),  # Fixed parameter name\n",
    "            #\"ema_js\": float(self.running_divergence),\n",
    "            #\"gain\": float(gain),\n",
    "        }\n",
    "\n",
    "    def find_next_token(self, generated_tokens, sequence_length):\n",
    "        previous_tokens = generated_tokens[:-sequence_length]\n",
    "        current_tokens = generated_tokens[-sequence_length:]\n",
    "\n",
    "        for i in range(len(previous_tokens) - sequence_length):\n",
    "            if previous_tokens[i:i + sequence_length] == current_tokens:\n",
    "                return generated_tokens[i + sequence_length]\n",
    "        return -1\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_with_leash(self,\n",
    "                            prompt: str,\n",
    "                            max_new_tokens: int = 128,\n",
    "                            temperature: float = 0.7,\n",
    "                            top_p: float = 0.95,\n",
    "                            repetition_penalty: float = 1.15,\n",
    "                            only_new_tokens: bool = False):\n",
    "\n",
    "\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)['input_ids']\n",
    "        generated = input_ids\n",
    "        past_key_values = None\n",
    "\n",
    "        if input_ids.shape[1] > 3:\n",
    "            first_token = input_ids[0, 1].item()\n",
    "            second_token = input_ids[0, 2].item()\n",
    "            print(f\"DEBUG: Prompt tokens: {input_ids[0].tolist()}\")\n",
    "            print(f\"DEBUG: First token: {first_token} = '{self.tokenizer.decode([first_token])}'\")\n",
    "            print(f\"DEBUG: Second token: {second_token} = '{self.tokenizer.decode([second_token])}'\")\n",
    "        else:\n",
    "            first_token = None\n",
    "            second_token = None\n",
    "\n",
    "        repetition_counter = 0\n",
    "\n",
    "        self.running_divergence = 0.0\n",
    "\n",
    "        # We run two forwards per step: base (no perturb), then perturbed (with current state)\n",
    "        for step in range(max_new_tokens):\n",
    "            # ---- BASE pass (perturbation off)\n",
    "            #print(f'base temperature: {self.attention_temperature}')\n",
    "            self.reset_to_base_model()\n",
    "            base_output = self.model(\n",
    "                input_ids=generated, \n",
    "                use_cache=True, \n",
    "                past_key_values=past_key_values, \n",
    "                output_hidden_states=True)\n",
    "            \n",
    "            base_logits = base_output.logits[:, -1, :]\n",
    "\n",
    "            self.apply_perturbation()\n",
    "            #print(f'perturbed temperature: {self.attention_temperature}')\n",
    "            perturbed_output = self.model(\n",
    "                input_ids=generated, \n",
    "                use_cache=True, \n",
    "                past_key_values=past_key_values, \n",
    "                output_hidden_states=True)\n",
    "\n",
    "            perturbed_logits = perturbed_output.logits[:, -1, :]\n",
    "\n",
    "            next_step = self.step(perturbed_logits, base_logits)\n",
    "            self.set_perturbation_parameters(**next_step)\n",
    "            past_key_values = base_output.past_key_values\n",
    "\n",
    "            # ---- Final logits for sampling: teacher blend\n",
    "            print(f'teacher blend: {self.teacher_blend}')\n",
    "            final_logits = (1 - self.teacher_blend) * perturbed_logits + self.teacher_blend * base_logits\n",
    "\n",
    "            # ---- Sample\n",
    "            final_logits = final_logits / temperature\n",
    "\n",
    "            if repetition_penalty != 1.0:\n",
    "                unique_recent_tokens = set(generated[0, :].tolist())# A set of unique recent tokens for efficient lookup\n",
    "                \n",
    "                flag = False\n",
    "                for token_id in unique_recent_tokens:\n",
    "                    # Apply the repetition penalty to only the tokens that have appeared recently\n",
    "                    flag = True\n",
    "                    if final_logits[0, token_id] < 0:\n",
    "                        final_logits[0, token_id] = final_logits[0, token_id] * repetition_penalty\n",
    "                    else:\n",
    "                        final_logits[0, token_id] = final_logits[0, token_id] / repetition_penalty\n",
    "\n",
    "                if flag:\n",
    "                    print(f'flag: {flag}')\n",
    "\n",
    "            probs = torch.softmax(final_logits, dim=-1)\n",
    "            if top_p < 1.0:\n",
    "                sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "                cum = torch.cumsum(sorted_probs, dim=-1)\n",
    "                mask = cum > top_p\n",
    "                mask[..., 1:] = mask[..., :-1].clone()\n",
    "                mask[..., 0] = False\n",
    "                sorted_probs[mask] = 0\n",
    "                sorted_probs = sorted_probs / sorted_probs.sum(dim=-1, keepdim=True).clamp_min(1e-9)\n",
    "                next_idx = torch.multinomial(sorted_probs, num_samples=1)\n",
    "                next_token = torch.gather(sorted_idx, -1, next_idx)\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            print(self.tokenizer.decode(next_token[0]))\n",
    "\n",
    "            generated = torch.cat([generated, next_token], dim=-1)\n",
    "\n",
    "            if next_token.item() == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "        if only_new_tokens:\n",
    "            new_tokens = generated[:, input_ids.shape[-1]:]\n",
    "            llm_response = self.tokenizer.decode(new_tokens[0], skip_special_tokens=True)\n",
    "        else:\n",
    "            llm_response = self.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "        return llm_response\n",
    "\n",
    "    #dtype = torch.bfloat16\n",
    "    #force_eager_attention: bool = True force either way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "model = LSDPerturbedLLM(\n",
    "    layer_start=21,                              # Start layer to perturb\n",
    "    layer_end=27,#30                               # Final layer to perturb  \n",
    "    attention_temperature_initial=1.60,          # Temperature > 1 flattens attention\n",
    "    attention_diagonal_penalty_initial=0.60,     # Reduced penalty for most recent key\n",
    "    js_tolerance=0.33,                          # Tolerated JS divergence\n",
    "    teacher_blend_min=0.20,                     # Min teacher blend weight\n",
    "    teacher_blend_max=0.50,                     # Max teacher blend weight\n",
    "    #js_softness = 0.1,                          # Sigmoid softness around the tolerance <- better name required\n",
    "    divergence_smoothing_factor = 0.2\n",
    ")\n",
    "\n",
    "# Generate text with the leash mechanism\n",
    "prompt = 'You feel a slipping feeling pulling you in'#As a friend describe what you see looking out at the sea\n",
    "print(f'Prompt: {prompt}')\n",
    "response = model.generate_with_leash(\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.33,\n",
    "    top_p=0.33,\n",
    "    repetition_penalty=2.0,#100\n",
    "    only_new_tokens=True\n",
    ")\n",
    "\n",
    "print(f'Response: {response}')\n",
    "\n",
    "#I am a person who is standing on an beach and I can describe in detail about how it feels to be able of being described as if Describing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "if repetition_penalty != 1.0:\n",
    "                recent_tokens = generated[0, -50:] if generated.shape[1] > 50 else generated[0]# Get recent tokens (last 50 tokens)\n",
    "\n",
    "                unique_recent_tokens = set(recent_tokens.tolist())# A set of unique recent tokens for efficient lookup\n",
    "                \n",
    "                flag = False\n",
    "                for token_id in unique_recent_tokens:\n",
    "                    # Apply the repetition penalty to only the tokens that have appeared recently\n",
    "                    flag = True\n",
    "                    if final_logits[0, token_id] < 0:\n",
    "                        final_logits[0, token_id] = final_logits[0, token_id] * repetition_penalty\n",
    "                    else:\n",
    "                        final_logits[0, token_id] = final_logits[0, token_id] / repetition_penalty\n",
    "\n",
    "                if flag:\n",
    "                    print(f'flag: {flag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            if second_token is not None:\n",
    "                if generated[0, -1].item() == first_token:\n",
    "                    min_logit_value = final_logits.min().item()\n",
    "                    final_logits[0, second_token] = min_logit_value\n",
    "\n",
    "                    print(f'second token addressed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_modification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
