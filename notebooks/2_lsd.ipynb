{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lsd\n",
    "#|export\n",
    "\n",
    "from perturbative_llm_cognition import core\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37797a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class LSDPerturbedLLM:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        layer_start: int = 21,                              # Start layer to perturb    \n",
    "        layer_end: int = 30,                                # Final layer to perturb\n",
    "        attention_temperature_target: float = 1.20,         # Temperature > 1 flattens attention (scores /= temperature)\n",
    "        attention_diagonal_penalty_target: float = 0.40,    # Subtract at most-recent key at decode (q_len==1)\n",
    "        swiglu_skew_target: float = 0.15,                   # Magnitude skew exponent\n",
    "        swiglu_noise_target: float = 0.12,                  # Structured noise scale (zero-mean) <- better name required\n",
    "        js_tolerance: float = 0.12,                         # Tolerated JS divergence before clamping gets strong\n",
    "        js_softness: float = 0.02,                          # Sigmoid softness around the tolerance <- better name required\n",
    "        divergence_smoothing: float = 0.8,                              # EMA smoothing for JS\n",
    "        teacher_blend_min: float = 0.05,                    # Min teacher blend weight\n",
    "        teacher_blend_max: float = 0.60,                    # Max teacher blend weight when drift is high\n",
    "        ):\n",
    "\n",
    "        self.layer_start = min(layer_start, 0)\n",
    "        self.layer_end = max(layer_end, 31)\n",
    "        self.attention_temperature_target = max(1.0, attention_temperature_target)\n",
    "        self.attention_diagonal_penalty_target = max(0.0, attention_diagonal_penalty_target)\n",
    "        self.swiglu_skew_target = max(0.0, swiglu_skew_target)\n",
    "        self.swiglu_noise_target = max(0.0, swiglu_noise_target)\n",
    "        self.js_tolerance = max(0.0, js_tolerance)\n",
    "        self.js_softness = max(0.0, js_softness)\n",
    "        self.divergence_smoothing = max(0.0, divergence_smoothing)\n",
    "        self.teacher_blend_min = max(0.0, teacher_blend_min)\n",
    "        self.teacher_blend_max = min(1.0, teacher_blend_max)\n",
    "\n",
    "        if self.teacher_blend_min > self.teacher_blend_max:\n",
    "            raise ValueError('Invalid teacher parameters')\n",
    "\n",
    "        self.set_perturbation_parameters(\n",
    "            attention_temperature=attention_temperature_target,\n",
    "            attention_diagonal_penalty=attention_diagonal_penalty_target,\n",
    "            teacher_blend=teacher_blend_min,\n",
    "            #swiglu_skew_target=swiglu_skew_target,\n",
    "            #swiglu_noise_target=swiglu_noise_target,\n",
    "        )\n",
    "\n",
    "        self.tokenizer, self.model = core.load_tokenizer_and_model()\n",
    "        self.model.config.attn_implementation = 'eager'\n",
    "        self.device = self.model.device\n",
    "\n",
    "    def set_perturbation_parameters(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Clamps all perturbation parameters to valid ranges.\n",
    "        \"\"\"\n",
    "\n",
    "        for parameter, value in kwargs.items():\n",
    "            if parameter in ['attention_temperature']:\n",
    "                setattr(self, parameter, max(1.0, value))\n",
    "            elif parameter in ['teacher_blend']:\n",
    "                setattr(self, parameter, max(0.0, min(1.0, value)))\n",
    "            else:\n",
    "                setattr(self, parameter, max(0.0, value))\n",
    "\n",
    "    def zero_perturbation_parameters(self):\n",
    "        #reset all key perturbation parameters\n",
    "        self.attention_temperature = 1.0\n",
    "        self.attention_diagonal_penalty = 0.0\n",
    "        #self.swiglu_skew = 0.0\n",
    "        #self.swiglu_noise = 0.0\n",
    "\n",
    "    def is_target_layer(self, index: int) -> bool:\n",
    "        #may be redundant\n",
    "        return self.layer_start <= index <= self.layer_end\n",
    "\n",
    "    def apply_perturbation(self):\n",
    "        self.apply_attention_perturbation()\n",
    "\n",
    "\n",
    "    def apply_attention_perturbation(self):        \n",
    "        for i, block in enumerate(self.model.model.layers):\n",
    "            block.self_attn.layer_idx = i\n",
    "\n",
    "            if not self.is_target_layer(i):\n",
    "                continue\n",
    "\n",
    "            attention = block.self_attn\n",
    "            original_forward = attention.forward\n",
    "\n",
    "            attention.forward = self.__get_wrapped_attention_forward(original_forward)# bind per-layer to avoid late-binding bugs\n",
    "\n",
    "    def __get_wrapped_attention_forward(self, original_forward):\n",
    "        def wrapped_forward(*args, **kwargs):\n",
    "            # patch F.softmax only for this call\n",
    "            original_softmax = F.softmax\n",
    "\n",
    "            def modified_softmax(x, dimensions=None, *_args, **_kwargs):\n",
    "                # Expect logits shape [batch, heads, q_len, k_len] and softmax along last dim\n",
    "                if x.dim() == 4 and (dimensions == -1 or dimensions == 3):\n",
    "                    y = x\n",
    "\n",
    "                    # temperature: divide logits (skip if == 1.0)\n",
    "                    tau = getattr(self, \"attention_temperature\", 1.0)\n",
    "                    if tau != 1.0:\n",
    "                        y = y / tau\n",
    "\n",
    "                    # decode step: q_len == 1 -> penalize last key\n",
    "                    diag = getattr(self, \"attention_diagonal_penalty\", 0.0)\n",
    "                    if diag != 0.0 and y.size(-2) == 1:\n",
    "                        y = y.clone()\n",
    "                        y[..., -1] = y[..., -1] - diag\n",
    "\n",
    "                    return original_softmax(y, dim=dimensions, *_args, **_kwargs)\n",
    "\n",
    "                # otherwise, leave it alone\n",
    "                return original_softmax(x, dim=dimensions, *_args, **_kwargs)\n",
    "\n",
    "            F.softmax = modified_softmax\n",
    "            try:\n",
    "                return original_forward(*args, **kwargs)\n",
    "            finally:\n",
    "                F.softmax = original_softmax\n",
    "\n",
    "        return wrapped_forward\n",
    "\n",
    "    @staticmethod\n",
    "    def js_divergence(p, q, eps=1e-8):\n",
    "        m = 0.5 * (p + q)\n",
    "        def kl(a,b):\n",
    "            return (a * (torch.log(a+eps) - torch.log(b+eps))).sum(-1)\n",
    "        return 0.5*kl(p, m) + 0.5*kl(q, m)\n",
    "\n",
    "    def step(self, pert_logits, base_logits):\n",
    "        # Distributions\n",
    "        p_base = torch.softmax(base_logits, dim=-1)\n",
    "        p_pert = torch.softmax(pert_logits, dim=-1)\n",
    "        # JS divergence (batch-mean scalar)\n",
    "        d = self.js_divergence(p_pert, p_base).mean().item()\n",
    "        # EMA\n",
    "        beta = self.divergence_smoothing\n",
    "        self.running_divergence = beta * self.running_divergence + (1 - beta) * d\n",
    "        # Gain (higher drift â†’ smaller g)\n",
    "        gain = torch.sigmoid(torch.tensor((self.js_tolerance - self.running_divergence) / self.js_softness)).item()\n",
    "\n",
    "        # Effective strengths\n",
    "        attention_temperature  = 1.0 + (self.attention_temperature_target - 1.0) * gain\n",
    "        attention_diagonal_penalty = self.attention_diagonal_penalty_target * gain\n",
    "        #skew_eff = self.cfg.swiglu_skew_target * g\n",
    "        #noise_eff= self.cfg.swiglu_noise_target * g\n",
    "\n",
    "        # Teacher blend increases as drift grows (g small)\n",
    "        teacher_blend = self.teacher_blend_min + (1 - gain) * (self.teacher_blend_max - self.teacher_blend_min)\n",
    "        return {\n",
    "            \"attention_temperature\": float(attention_temperature),\n",
    "            \"attention_diagonal_penalty\": float(attention_diagonal_penalty),\n",
    "            #\"skew_eff\": float(skew_eff),\n",
    "            #\"noise_eff\": float(noise_eff),\n",
    "            \"teaching_blend\": float(teacher_blend),\n",
    "            #\"ema_js\": float(self.running_divergence),\n",
    "            #\"gain\": float(gain),\n",
    "        }\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_with_leash(self,\n",
    "                            prompt: str,\n",
    "                            max_new_tokens: int = 128,\n",
    "                            temperature: float = 0.7,\n",
    "                            top_p: float = 0.95):\n",
    "\n",
    "\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)['input_ids']\n",
    "        generated = input_ids\n",
    "        past_key_values = None\n",
    "\n",
    "        self.running_divergence = 0.0\n",
    "\n",
    "        # We run two forwards per step: base (no perturb), then perturbed (with current state)\n",
    "        for step in range(max_new_tokens):\n",
    "            # ---- BASE pass (perturbation off)\n",
    "            \n",
    "            perturbed_output = self.model(\n",
    "                input_ids=generated, \n",
    "                use_cache=True, \n",
    "                past_key_values=past_key_values, \n",
    "                output_hidden_states=True)\n",
    "\n",
    "            perturbed_logits = perturbed_output.logits[:, -1, :]\n",
    "\n",
    "            self.zero_perturbation_parameters()\n",
    "            base_output = self.model(\n",
    "                input_ids=generated, \n",
    "                use_cache=True, \n",
    "                past_key_values=past_key_values, \n",
    "                output_hidden_states=True)\n",
    "\n",
    "            \n",
    "            base_logits = base_output.logits[:, -1, :]\n",
    "\n",
    "\n",
    "            next_step = self.step(perturbed_logits, base_logits)\n",
    "            self.set_perturbation_parameters(**next_step)\n",
    "            past_key_values = perturbed_output.past_key_values\n",
    "\n",
    "\n",
    "            # ---- Final logits for sampling: teacher blend\n",
    "            final_logits = (1 - self.teacher_blend) * perturbed_logits + self.teacher_blend * base_logits\n",
    "\n",
    "            # ---- Sample\n",
    "            final_logits = final_logits / max(1e-5, temperature)\n",
    "            probs = torch.softmax(final_logits, dim=-1)\n",
    "            if top_p < 1.0:\n",
    "                sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "                cum = torch.cumsum(sorted_probs, dim=-1)\n",
    "                mask = cum > top_p\n",
    "                mask[..., 1:] = mask[..., :-1].clone()\n",
    "                mask[..., 0] = False\n",
    "                sorted_probs[mask] = 0\n",
    "                sorted_probs = sorted_probs / sorted_probs.sum(dim=-1, keepdim=True).clamp_min(1e-9)\n",
    "                next_idx = torch.multinomial(sorted_probs, num_samples=1)\n",
    "                next_token = torch.gather(sorted_idx, -1, next_idx)\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            generated = torch.cat([generated, next_token], dim=-1)\n",
    "\n",
    "        return self.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "    #dtype = torch.bfloat16\n",
    "    #force_eager_attention: bool = True force either way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "model = LSDPerturbedLLM(\n",
    "    layer_start=21,                              # Start layer to perturb\n",
    "    layer_end=30,                               # Final layer to perturb  \n",
    "    attention_temperature_target=1.20,          # Temperature > 1 flattens attention\n",
    "    attention_diagonal_penalty_target=0.40,     # Penalty for most recent key\n",
    "    js_tolerance=0.12,                          # Tolerated JS divergence\n",
    "    teacher_blend_min=0.05,                     # Min teacher blend weight\n",
    "    teacher_blend_max=0.60,                     # Max teacher blend weight\n",
    ")\n",
    "\n",
    "# Generate text with the leash mechanism\n",
    "prompt = 'Describe what you see looking out at the sea'\n",
    "print(f'Prompt: {prompt}')\n",
    "response = model.generate_with_leash(\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "print(f'Response: {response}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
